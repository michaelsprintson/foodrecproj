{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 23:49:25.482552: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-09 23:49:25.505898: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-09 23:49:25.506376: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-09 23:49:26.028513: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "from recommenders.utils.constants import SEED\n",
    "from recommenders.utils import tf_utils\n",
    "from recommenders.datasets.pandas_df_utils import user_item_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacsv = pd.read_csv(\"data/new_user_recipe.csv\")\n",
    "datacsv.columns = [\"idx\", \"itemID\",\"userID\", \"text\", \"rating\"]\n",
    "datacsv.drop([\"idx\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "import ast\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "re_l = [\n",
    "    lambda x: re.sub(\"\\d+\", \"\", x),    \n",
    "    lambda x: re.sub(\"\\(.*\\)\", \"\", x),\n",
    "    lambda x: x.replace(\"/ \", \"\"),\n",
    "    lambda x: x.replace(\"cups\", \"\").replace(\"cup\", \"\").replace(\"tablespoons\", \"\").replace(\"tablespoon\", \"\").replace(\"teaspoons\", \"\").replace(\"teaspoon\", \"\"),\n",
    "    lambda x: x.strip(\" \"),\n",
    "    lambda x: x.strip(\"s\")\n",
    "]\n",
    "ing_counter = defaultdict(int)\n",
    "def loop_re(x):\n",
    "    for rel in re_l:\n",
    "        x = rel(x.split(\",\")[0])\n",
    "    ing_counter[x] += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225602it [00:02, 75422.79it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"finished_reviews.txt\",'r') as fr:\n",
    "    finished_reviews = set(ast.literal_eval(\"[\" + fr.readline() + \"]\"))\n",
    "\n",
    "e_f = {}\n",
    "\n",
    "with open(\"allrecipes-recipes.json\") as f:\n",
    "    for i, jsonOb in tqdm(enumerate(f)):\n",
    "        if i in finished_reviews:\n",
    "            recipesDict = json.loads(jsonOb)\n",
    "            ing = [loop_re(i) for i in recipesDict[\"ingredients\"]]\n",
    "            e_f[i] = ing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = sorted([(k,v) for k,v in dict(ing_counter).items()], key = lambda x: x[1])[-len(ing_counter)//50][1]\n",
    "kept_ings = set([k for k,v in dict(ing_counter).items() if v > threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8979 179\n"
     ]
    }
   ],
   "source": [
    "print(len(ing_counter), len(kept_ings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16376/16376 [00:03<00:00, 5304.95it/s]\n"
     ]
    }
   ],
   "source": [
    "datacsv['ing'] = None\n",
    "for i in tqdm(finished_reviews):\n",
    "    r = e_f[i]\n",
    "    r = [i for i in r if i in kept_ings]\n",
    "    datacsv.loc[datacsv['itemID'] == i,\"ing\"] = r.__repr__()\n",
    "datacsv['ing'] = datacsv['ing'].map(lambda x: ast.literal_eval(x) if not x is None else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num ings: 161\n"
     ]
    }
   ],
   "source": [
    "genres_encoder = sklearn.preprocessing.MultiLabelBinarizer()\n",
    "datacsv[\"ing\"] = genres_encoder.fit_transform(\n",
    "    datacsv[\"ing\"]\n",
    ").tolist()\n",
    "print(\"num ings:\", len(genres_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_random_split(datacsv, ratio=0.75, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 294 items and 480 users in the dataset\n"
     ]
    }
   ],
   "source": [
    "items = datacsv.drop_duplicates(\"itemID\")[[\"itemID\", \"ing\"]].reset_index(drop=True)\n",
    "item_feat_shape = len(items[\"ing\"][0])\n",
    "users = datacsv.drop_duplicates(\"userID\")[[\"userID\"]].reset_index(drop=True)\n",
    "print(\"Total {} items and {} users in the dataset\".format(len(items), len(users)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = \"wide_deep\"\n",
    "STEPS = 22500  # Number of batches to train\n",
    "BATCH_SIZE = 4\n",
    "# Wide (linear) model hyperparameters\n",
    "LINEAR_OPTIMIZER = \"adagrad\"\n",
    "LINEAR_OPTIMIZER_LR = 0.001  # Learning rate\n",
    "LINEAR_L1_REG = 0.1           # Regularization rate for FtrlOptimizer\n",
    "LINEAR_L2_REG = 0.0\n",
    "LINEAR_MOMENTUM = 0.0         # Momentum for MomentumOptimizer or RMSPropOptimizer\n",
    "# DNN model hyperparameters\n",
    "DNN_OPTIMIZER = \"adadelta\"\n",
    "DNN_OPTIMIZER_LR = 0.1\n",
    "DNN_L1_REG = 0.1           # Regularization rate for FtrlOptimizer\n",
    "DNN_L2_REG = 0.0\n",
    "DNN_MOMENTUM = 0.0         # Momentum for MomentumOptimizer or RMSPropOptimizer\n",
    "# Layer dimensions. Defined as follows to make this notebook runnable from Hyperparameter tuning services like AzureML Hyperdrive\n",
    "DNN_HIDDEN_LAYER_1 = 0     # Set 0 to not use this layer\n",
    "DNN_HIDDEN_LAYER_2 = 64    # Set 0 to not use this layer\n",
    "DNN_HIDDEN_LAYER_3 = 128   # Set 0 to not use this layer\n",
    "DNN_HIDDEN_LAYER_4 = 512   # Note, at least one layer should have nodes.\n",
    "DNN_HIDDEN_UNITS = [h for h in [DNN_HIDDEN_LAYER_1, DNN_HIDDEN_LAYER_2, DNN_HIDDEN_LAYER_3, DNN_HIDDEN_LAYER_4] if h > 0]\n",
    "DNN_USER_DIM = 32          # User embedding feature dimension\n",
    "DNN_ITEM_DIM = 16          # Item embedding feature dimension\n",
    "DNN_DROPOUT = 0.8\n",
    "DNN_BATCH_NORM = 1         # 1 to use batch normalization, 0 if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import recommenders.models.wide_deep.wide_deep_utils as wide_deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wide feature specs:\n",
      "\t VocabularyListCategoricalColumn(key='userID', vocabulary_list=(641, 389, 892, 1546, 1888, 1857, 2222 ...\n",
      "\t VocabularyListCategoricalColumn(key='itemID', vocabulary_list=(34, 110, 113, 125, 152, 157, 199, 202 ...\n",
      "\t CrossedColumn(keys=(VocabularyListCategoricalColumn(key='userID', vocabulary_list=(641, 389, 892, 15 ...\n",
      "Deep feature specs:\n",
      "\t EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='userID', vocabulary_list=(64 ...\n",
      "\t EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='itemID', vocabulary_list=(34 ...\n",
      "\t NumericColumn(key='ing', shape=(161,), default_value=None, dtype=tf.float32, normalizer_fn=None) ...\n"
     ]
    }
   ],
   "source": [
    "save_checkpoints_steps = max(1, STEPS // 5)\n",
    "\n",
    "wide_columns, deep_columns = wide_deep.build_feature_columns(\n",
    "    users=users[\"userID\"].values,\n",
    "    items=items[\"itemID\"].values,\n",
    "    user_col=\"userID\",\n",
    "    item_col=\"itemID\",\n",
    "    item_feat_col=\"ing\",\n",
    "    crossed_feat_dim=1000,\n",
    "    user_dim=DNN_USER_DIM,\n",
    "    item_dim=DNN_ITEM_DIM,\n",
    "    item_feat_shape=item_feat_shape,\n",
    "    model_type=MODEL_TYPE,\n",
    ")\n",
    "\n",
    "print(\"Wide feature specs:\")\n",
    "for c in wide_columns:\n",
    "    print(\"\\t\", str(c)[:100], \"...\")\n",
    "print(\"Deep feature specs:\")\n",
    "for c in deep_columns:\n",
    "    print(\"\\t\", str(c)[:100], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import TemporaryDirectory\n",
    "TMP_DIR = TemporaryDirectory()\n",
    "model_dir = TMP_DIR.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpwt_h1ple', '_tf_random_seed': 42, '_save_summary_steps': 100, '_save_checkpoints_steps': 4500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 2250, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = wide_deep.build_model(\n",
    "    model_dir=model_dir,\n",
    "    wide_columns=wide_columns,\n",
    "    deep_columns=deep_columns,\n",
    "    linear_optimizer=tf_utils.build_optimizer(LINEAR_OPTIMIZER, LINEAR_OPTIMIZER_LR, **{\n",
    "        'l1_regularization_strength': LINEAR_L1_REG,\n",
    "        'l2_regularization_strength': LINEAR_L2_REG,\n",
    "        'momentum': LINEAR_MOMENTUM,\n",
    "    }),\n",
    "    dnn_optimizer=tf_utils.build_optimizer(DNN_OPTIMIZER, DNN_OPTIMIZER_LR, **{\n",
    "        'l1_regularization_strength': DNN_L1_REG,\n",
    "        'l2_regularization_strength': DNN_L2_REG,\n",
    "        'momentum': DNN_MOMENTUM,  \n",
    "    }),\n",
    "    dnn_hidden_units=DNN_HIDDEN_UNITS,\n",
    "    dnn_dropout=DNN_DROPOUT,\n",
    "    dnn_batch_norm=(DNN_BATCH_NORM==1),\n",
    "    log_every_n_iter=max(1, STEPS//10),  # log 10 times\n",
    "    save_checkpoints_steps=save_checkpoints_steps,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {\n",
    "    'col_user': \"userID\",\n",
    "    'col_item': \"itemID\",\n",
    "    'col_rating': \"rating\",\n",
    "    'col_prediction': \"predict\",\n",
    "}\n",
    "\n",
    "# Prepare ranking evaluation set, i.e. get the cross join of all user-item pairs\n",
    "ranking_pool = user_item_pairs(\n",
    "    user_df=users,\n",
    "    item_df=items,\n",
    "    user_col=\"userID\",\n",
    "    item_col=\"itemID\",\n",
    "    user_item_filter_df=train,  # Remove seen items\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "hooks = []\n",
    "train_fn = tf_utils.pandas_input_fn(\n",
    "    df=train,\n",
    "    y_col=\"rating\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_epochs=None,  # We use steps=TRAIN_STEPS instead.\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\n",
    "    \"Training steps = {}, Batch size = {} (num epochs = {})\"\n",
    "    .format(STEPS, BATCH_SIZE, (STEPS*BATCH_SIZE)//len(train))\n",
    ")\n",
    "\n",
    "try:\n",
    "    model.train(\n",
    "        input_fn=train_fn,\n",
    "        hooks=hooks,\n",
    "        steps=STEPS\n",
    "    )\n",
    "except tf.train.NanLossDuringTrainingError:\n",
    "    import warnings\n",
    "    warnings.warn(\n",
    "        \"Training stopped with NanLossDuringTrainingError. \"\n",
    "        \"Try other optimizers, smaller batch size and/or smaller learning rate.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import recommenders.evaluation.python_evaluation as evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RATING_METRICS = [\n",
    "#     evaluator.map_at_k.__name__,\n",
    "#     evaluator.ndcg_at_k.__name__,\n",
    "#     evaluator.precision_at_k.__name__,\n",
    "#     evaluator.recall_at_k.__name__,\n",
    "# ]\n",
    "# if len(RATING_METRICS) > 0:\n",
    "#     predictions = list(model.predict(input_fn=tf_utils.pandas_input_fn(df=test)))\n",
    "#     prediction_df = test.drop(\"rating\", axis=1)\n",
    "#     prediction_df[\"predict\"] = [p['predictions'][0] for p in predictions]\n",
    "    \n",
    "#     rating_results = {}\n",
    "#     for m in RATING_METRICS:\n",
    "#         result = evaluator.metrics[m](test, prediction_df, **cols)\n",
    "#         rating_results[m] = result\n",
    "#     print(rating_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(model.predict(input_fn=tf_utils.pandas_input_fn(df=test)))\n",
    "prediction_df = test.drop(\"rating\", axis=1)\n",
    "prediction_df[\"predict\"] = [p['predictions'][0] for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df_max = prediction_df['predict'].max()\n",
    "prediction_df_min = prediction_df['predict'].min()\n",
    "prediction_df['predict'] = (prediction_df['predict'] - prediction_df_min) / (prediction_df_max - prediction_df_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "eval_map = map_at_k(test, prediction_df, col_prediction='predict', k=10)\n",
    "eval_ndcg = ndcg_at_k(test, prediction_df, col_prediction='predict', k=10)\n",
    "eval_precision = precision_at_k(test, prediction_df, col_prediction='predict', k=10)\n",
    "eval_recall = recall_at_k(test, prediction_df, col_prediction='predict', k=10)\n",
    "\n",
    "print(\"MAP:\\t%f\" % eval_map,\n",
    "      \"NDCG:\\t%f\" % eval_ndcg,\n",
    "      \"Precision@K:\\t%f\" % eval_precision,\n",
    "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
