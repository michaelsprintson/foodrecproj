{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 23:37:19.360739: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-09 23:37:19.383464: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-09 23:37:19.383942: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-09 23:37:19.891450: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "from recommenders.utils.constants import SEED\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.models.deeprec.models.graphrec.lightgcn import LightGCN\n",
    "from recommenders.models.deeprec.DataModel.ImplicitCF import ImplicitCF\n",
    "from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "from recommenders.models.deeprec.deeprec_utils import prepare_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = \"./lightgcn.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.9/site-packages/recommenders/models/deeprec/DataModel/ImplicitCF.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = train if test is None else train.append(test)\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 128\n",
    "TOP_K = 10\n",
    "\n",
    "# datacsv = pd.read_csv(\"data/user_recipe.csv\")\n",
    "# datacsv.columns = [\"userID\", \"itemID\", \"rating\", \"modifyDate\"]\n",
    "datacsv_new = pd.read_csv(\"data/new_user_recipe.csv\")\n",
    "datacsv_new.columns = [\"idx\", \"itemID\",\"userID\", \"text\", \"rating\"]\n",
    "datacsv_new.drop([\"idx\"], inplace=True, axis=1)\n",
    "\n",
    "# train, test = python_random_split(datacsv, 0.75)\n",
    "train_new, test_new = python_random_split(datacsv_new, 0.75)\n",
    "# data = ImplicitCF(train=train, test=test, seed=SEED)\n",
    "data_new = ImplicitCF(train=train_new, test=train_new, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.train_loader(model.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users, pos_items, neg_items = model.data.train_loader(model.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = prepare_hparams(yaml_file,\n",
    "                          n_layers=3,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          epochs=EPOCHS,\n",
    "                          learning_rate=0.005,\n",
    "                          eval_epoch=5,\n",
    "                          top_k=TOP_K,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 23:39:40.932085: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-09 23:39:40.932373: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-09 23:39:40.932591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-09 23:39:40.932809: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-09 23:39:40.932995: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model = LightGCN(hparams, data=data_new, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (train)8.1s: train loss = 0.62979 = (mf)0.62937 + (embed)0.00042\n",
      "Epoch 2 (train)8.5s: train loss = 0.59511 = (mf)0.59422 + (embed)0.00089\n",
      "Epoch 3 (train)8.5s: train loss = 0.54935 = (mf)0.54753 + (embed)0.00182\n",
      "Epoch 4 (train)8.4s: train loss = 0.49177 = (mf)0.48851 + (embed)0.00325\n",
      "Epoch 5 (train)8.5s + (eval)0.3s: train loss = 0.43424 = (mf)0.42929 + (embed)0.00495, recall = 0.00000, ndcg = 0.00000, precision = 0.00000, map = 0.00000\n",
      "Epoch 6 (train)8.5s: train loss = 0.39006 = (mf)0.38334 + (embed)0.00672\n",
      "Epoch 7 (train)8.4s: train loss = 0.35072 = (mf)0.34228 + (embed)0.00844\n",
      "Epoch 8 (train)8.5s: train loss = 0.32167 = (mf)0.31158 + (embed)0.01010\n",
      "Epoch 9 (train)8.4s: train loss = 0.29344 = (mf)0.28174 + (embed)0.01169\n",
      "Epoch 10 (train)8.5s + (eval)0.3s: train loss = 0.27190 = (mf)0.25870 + (embed)0.01321, recall = 0.00000, ndcg = 0.00000, precision = 0.00000, map = 0.00000\n",
      "Epoch 11 (train)8.4s: train loss = 0.25263 = (mf)0.23799 + (embed)0.01464\n",
      "Epoch 12 (train)8.5s: train loss = 0.23800 = (mf)0.22203 + (embed)0.01597\n",
      "Epoch 13 (train)8.5s: train loss = 0.22363 = (mf)0.20636 + (embed)0.01727\n",
      "Epoch 14 (train)8.5s: train loss = 0.21204 = (mf)0.19355 + (embed)0.01849\n",
      "Epoch 15 (train)8.4s + (eval)0.3s: train loss = 0.20371 = (mf)0.18404 + (embed)0.01967, recall = 0.00000, ndcg = 0.00000, precision = 0.00000, map = 0.00000\n",
      "Epoch 16 (train)8.4s: train loss = 0.19309 = (mf)0.17232 + (embed)0.02077\n",
      "Epoch 17 (train)8.4s: train loss = 0.18485 = (mf)0.16302 + (embed)0.02183\n",
      "Epoch 18 (train)8.5s: train loss = 0.17871 = (mf)0.15589 + (embed)0.02282\n",
      "Epoch 19 (train)8.5s: train loss = 0.17473 = (mf)0.15094 + (embed)0.02380\n",
      "Epoch 20 (train)8.4s + (eval)0.3s: train loss = 0.16927 = (mf)0.14457 + (embed)0.02470, recall = 0.00000, ndcg = 0.00000, precision = 0.00000, map = 0.00000\n",
      "Epoch 21 (train)8.4s: train loss = 0.16280 = (mf)0.13727 + (embed)0.02554\n",
      "Epoch 22 (train)8.3s: train loss = 0.16131 = (mf)0.13493 + (embed)0.02638\n",
      "Epoch 23 (train)8.5s: train loss = 0.15669 = (mf)0.12953 + (embed)0.02716\n",
      "Epoch 24 (train)8.5s: train loss = 0.15230 = (mf)0.12443 + (embed)0.02787\n",
      "Epoch 25 (train)8.5s + (eval)0.3s: train loss = 0.15033 = (mf)0.12170 + (embed)0.02863, recall = 0.00000, ndcg = 0.00000, precision = 0.00000, map = 0.00000\n",
      "Epoch 26 (train)8.5s: train loss = 0.14719 = (mf)0.11788 + (embed)0.02931\n",
      "Epoch 27 (train)8.5s: train loss = 0.14427 = (mf)0.11427 + (embed)0.03000\n",
      "Epoch 28 (train)8.4s: train loss = 0.14145 = (mf)0.11081 + (embed)0.03064\n",
      "Epoch 29 (train)8.4s: train loss = 0.13994 = (mf)0.10872 + (embed)0.03121\n",
      "Epoch 30 (train)8.5s + (eval)0.3s: train loss = 0.13839 = (mf)0.10660 + (embed)0.03180, recall = 0.00000, ndcg = 0.00000, precision = 0.00000, map = 0.00000\n",
      "Epoch 31 (train)8.4s: train loss = 0.13669 = (mf)0.10438 + (embed)0.03231\n",
      "Epoch 32 (train)8.5s: train loss = 0.13699 = (mf)0.10416 + (embed)0.03283\n",
      "Epoch 33 (train)8.4s: train loss = 0.13460 = (mf)0.10123 + (embed)0.03337\n",
      "Epoch 34 (train)8.5s: train loss = 0.13134 = (mf)0.09750 + (embed)0.03384\n",
      "Epoch 35 (train)8.4s + (eval)0.3s: train loss = 0.13328 = (mf)0.09894 + (embed)0.03433, recall = 0.00000, ndcg = 0.00000, precision = 0.00000, map = 0.00000\n",
      "Epoch 36 (train)8.4s: train loss = 0.13004 = (mf)0.09529 + (embed)0.03474\n",
      "Epoch 37 (train)8.4s: train loss = 0.12842 = (mf)0.09321 + (embed)0.03520\n",
      "Epoch 38 (train)8.5s: train loss = 0.12672 = (mf)0.09112 + (embed)0.03560\n",
      "Epoch 39 (train)8.4s: train loss = 0.12804 = (mf)0.09202 + (embed)0.03602\n",
      "Epoch 40 (train)8.5s + (eval)0.3s: train loss = 0.12509 = (mf)0.08869 + (embed)0.03639, recall = 0.00000, ndcg = 0.00000, precision = 0.00000, map = 0.00000\n",
      "Epoch 41 (train)8.5s: train loss = 0.12458 = (mf)0.08778 + (embed)0.03680\n",
      "Epoch 42 (train)8.5s: train loss = 0.12345 = (mf)0.08633 + (embed)0.03712\n",
      "Epoch 43 (train)8.5s: train loss = 0.12252 = (mf)0.08503 + (embed)0.03750\n",
      "Epoch 44 (train)8.5s: train loss = 0.12238 = (mf)0.08452 + (embed)0.03786\n",
      "Epoch 45 (train)8.5s + (eval)0.3s: train loss = 0.11934 = (mf)0.08114 + (embed)0.03820, recall = 0.00000, ndcg = 0.00000, precision = 0.00000, map = 0.00000\n",
      "Epoch 46 (train)8.5s: train loss = 0.12135 = (mf)0.08286 + (embed)0.03849\n",
      "Epoch 47 (train)8.5s: train loss = 0.12152 = (mf)0.08273 + (embed)0.03879\n",
      "Epoch 48 (train)8.4s: train loss = 0.11914 = (mf)0.08001 + (embed)0.03913\n",
      "Epoch 49 (train)8.5s: train loss = 0.11857 = (mf)0.07916 + (embed)0.03941\n",
      "Epoch 50 (train)8.5s + (eval)0.3s: train loss = 0.11954 = (mf)0.07989 + (embed)0.03966, recall = 0.00000, ndcg = 0.00000, precision = 0.00000, map = 0.00000\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_scores = model.recommend_k_items(test_new, top_k=TOP_K, remove_seen=True)\n",
    "\n",
    "topk_scores_max = topk_scores['prediction'].max()\n",
    "topk_scores_min = topk_scores['prediction'].min()\n",
    "topk_scores['prediction'] = (topk_scores['prediction'] - topk_scores_min) / (topk_scores_max - topk_scores_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP:\t0.004728\n",
      "NDCG:\t0.162500\n",
      "Precision@K:\t0.162500\n",
      "Recall@K:\t0.004332\n"
     ]
    }
   ],
   "source": [
    "eval_map = map_at_k(test_new, topk_scores, k=1)\n",
    "eval_ndcg = ndcg_at_k(test_new, topk_scores, k=1)\n",
    "eval_precision = precision_at_k(test_new, topk_scores, k=1)\n",
    "eval_recall = recall_at_k(test_new, topk_scores, k=1)\n",
    "\n",
    "print(\"MAP:\\t%f\" % eval_map,\n",
    "      \"NDCG:\\t%f\" % eval_ndcg,\n",
    "      \"Precision@K:\\t%f\" % eval_precision,\n",
    "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
